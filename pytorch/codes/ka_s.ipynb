{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e9a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3dbadac",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    'batch_size': 16,\n",
    "    'epochs': 300,\n",
    "#     'epochs': 2,  # for test\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 1e-6,\n",
    "    'es_patience': 10,\n",
    "}\n",
    "\n",
    "time_now = (datetime.datetime.now()+datetime.timedelta(hours=9)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "configs['time_now'] = time_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4026848",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train_prob1.pkl', 'rb') as f:\n",
    "    train_origin = pickle.load(f)\n",
    "with open('../data/test_prob1.pkl', 'rb') as f:\n",
    "    test_origin = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba1cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_origin.copy(), test_origin.copy()\n",
    "\n",
    "train = train[:50000]\n",
    "\n",
    "train['status'] = train['status'].apply(lambda x: int(x[-1]))\n",
    "test['status'] = test['status'].apply(lambda x: int(x[-1]))\n",
    "\n",
    "train, valid = train_test_split(train)\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c451b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = ['distance', 'fare', 'call_count', 'dispatch_count', 'driver_count']\n",
    "target_col = 'status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0387f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device {device}')\n",
    "configs['device'] = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98e2b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaxiDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.data.iloc[idx, :-1]\n",
    "        inputs = torch.tensor(inputs).type(torch.float)\n",
    "        targets = self.data.iloc[idx, -1]\n",
    "        targets = torch.tensor(targets).type(torch.long)\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e227b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_input = train[input_cols + [target_col]]\n",
    "valid_to_input = valid[input_cols + [target_col]]\n",
    "test_to_input = test[input_cols + [target_col]]\n",
    "\n",
    "train_ds = TaxiDataset(train_to_input)\n",
    "valid_ds = TaxiDataset(valid_to_input)\n",
    "test_ds = TaxiDataset(test_to_input)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=configs['batch_size'], shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=configs['batch_size'])\n",
    "test_dl = DataLoader(test_ds, batch_size=configs['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f561e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNModel(\n",
      "  (dense_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=16, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNModel, self).__init__()\n",
    "        self.dense_relu_stack = nn.Sequential(\n",
    "            nn.Linear(len(input_cols), 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 3),\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        outputs = self.dense_relu_stack(inputs)\n",
    "        return outputs\n",
    "    \n",
    "model = NNModel().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35ea94d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = Adam(model.parameters(), lr=configs['learning_rate'])\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=configs['learning_rate']/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ac8c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_dl, model, loss_fn, optimizer, lr_scheduler, configs):\n",
    "    \n",
    "    n_total = len(train_dl.dataset)\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(train_dl):\n",
    "        X, y = X.to(configs['device']), y.to(configs['device'])\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        acc = (pred.argmax(axis=1) == y).sum().item()\n",
    "        \n",
    "        train_loss += loss.item()/n_total\n",
    "        train_acc += acc/n_total\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        check = (n_total//configs['batch_size']+1)//5\n",
    "        if batch%check == check-1:\n",
    "            train_loss_tmp = train_loss*n_total/(batch+1)/configs['batch_size']\n",
    "            train_acc_tmp = train_acc*n_total/(batch+1)/configs['batch_size']\n",
    "            current = batch*configs['batch_size']\n",
    "            print(f'loss: {train_loss_tmp:>10f}, acc: {train_acc_tmp*100:>10f} [{current:>5d}/{n_total:>5d}]')\n",
    "            \n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85eea51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dl, model, loss_fn, configs, return_pred=False):\n",
    "    \n",
    "    n_total = len(dl.dataset)\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    \n",
    "    if return_pred:\n",
    "        pred_arr = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dl:\n",
    "            X, y = X.to(configs['device']), y.to(configs['device'])\n",
    "\n",
    "            pred = model(X)\n",
    "            if return_pred:\n",
    "                pred_arr.extend(pred.tolist())\n",
    "            loss = loss_fn(pred, y)\n",
    "            acc = (pred.argmax(axis=1) == y).sum().item()\n",
    "\n",
    "            total_loss += loss.item()/n_total\n",
    "            total_acc += acc/n_total\n",
    "            \n",
    "    if return_pred:\n",
    "        return total_loss, total_acc, np.array(pred_arr)\n",
    "    else:\n",
    "        return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "959e7b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Learning Rate 0.001000\n",
      "---------------------------------\n",
      "loss: 171.858952, acc:  40.918803 [ 7472/37500]\n",
      "loss:  89.953350, acc:  42.327724 [14960/37500]\n",
      "loss:  62.344645, acc:  42.997685 [22448/37500]\n",
      "loss:  48.365558, acc:  43.352698 [29936/37500]\n",
      "loss:  39.616196, acc:  43.955662 [37424/37500]\n",
      "\n",
      "Train Loss: 39.565042, Train Acc: 43.952%\n",
      "Valid Loss: 2.802052, Valid Acc: 50.480%\n",
      "\n",
      "Break the best valid loss\n",
      "\t     inf -> 2.802052\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "Learning Rate 0.000672\n",
      "---------------------------------\n",
      "loss:   6.602284, acc:  43.643162 [ 7472/37500]\n",
      "loss:   7.056515, acc:  44.477831 [14960/37500]\n",
      "loss:   6.960096, acc:  44.689281 [22448/37500]\n",
      "loss:   6.770092, acc:  44.858440 [29936/37500]\n",
      "loss:   6.548911, acc:  44.863782 [37424/37500]\n",
      "\n",
      "Train Loss: 6.545806, Train Acc: 44.845%\n",
      "Valid Loss: 3.417785, Valid Acc: 50.552%\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "Learning Rate 0.000141\n",
      "---------------------------------\n",
      "loss:   5.428139, acc:  44.537927 [ 7472/37500]\n",
      "loss:   4.898378, acc:  45.252404 [14960/37500]\n",
      "loss:   5.082127, acc:  45.183405 [22448/37500]\n",
      "loss:   5.130281, acc:  44.861779 [29936/37500]\n",
      "loss:   5.135063, acc:  44.743590 [37424/37500]\n",
      "\n",
      "Train Loss: 5.134123, Train Acc: 44.752%\n",
      "Valid Loss: 10.006306, Valid Acc: 50.272%\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Learning Rate 0.000141\n",
      "---------------------------------\n",
      "loss:   3.456689, acc:  46.808226 [ 7472/37500]\n",
      "loss:   3.594730, acc:  45.873397 [14960/37500]\n",
      "loss:   3.749004, acc:  45.837785 [22448/37500]\n",
      "loss:   3.837871, acc:  45.910123 [29936/37500]\n",
      "loss:   3.640951, acc:  45.988248 [37424/37500]\n",
      "\n",
      "Train Loss: 3.637972, Train Acc: 46.003%\n",
      "Valid Loss: 1.031863, Valid Acc: 52.424%\n",
      "\n",
      "Break the best valid loss\n",
      "\t2.802052 -> 1.031863\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Learning Rate 0.000672\n",
      "---------------------------------\n",
      "loss:   3.009641, acc:  47.262286 [ 7472/37500]\n",
      "loss:   3.569169, acc:  46.481036 [14960/37500]\n",
      "loss:   3.582219, acc:  46.581197 [22448/37500]\n",
      "loss:   3.488117, acc:  46.537794 [29936/37500]\n",
      "loss:   3.283802, acc:  46.431624 [37424/37500]\n",
      "\n",
      "Train Loss: 3.281008, Train Acc: 46.440%\n",
      "Valid Loss: 3.053408, Valid Acc: 47.280%\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Learning Rate 0.001000\n",
      "---------------------------------\n",
      "loss:   2.441586, acc:  46.287393 [ 7472/37500]\n",
      "loss:   2.234582, acc:  46.668002 [14960/37500]\n",
      "loss:   2.397020, acc:  46.630164 [22448/37500]\n",
      "loss:   2.462558, acc:  46.521100 [29936/37500]\n",
      "loss:   2.497353, acc:  46.672009 [37424/37500]\n",
      "\n",
      "Train Loss: 2.496196, Train Acc: 46.675%\n",
      "Valid Loss: 1.757721, Valid Acc: 45.296%\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Learning Rate 0.000672\n",
      "---------------------------------\n",
      "loss:   2.580606, acc:  47.716346 [ 7472/37500]\n",
      "loss:   2.296138, acc:  48.050214 [14960/37500]\n",
      "loss:   2.109184, acc:  48.134793 [22448/37500]\n",
      "loss:   1.905023, acc:  48.240518 [29936/37500]\n",
      "loss:   1.723998, acc:  47.956731 [37424/37500]\n",
      "\n",
      "Train Loss: 1.722778, Train Acc: 47.968%\n",
      "Valid Loss: 0.954676, Valid Acc: 47.800%\n",
      "\n",
      "Break the best valid loss\n",
      "\t1.031863 -> 0.954676\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Learning Rate 0.000141\n",
      "---------------------------------\n",
      "loss:   0.934132, acc:  47.329060 [ 7472/37500]\n",
      "loss:   0.935163, acc:  46.721421 [14960/37500]\n",
      "loss:   0.938274, acc:  46.336360 [22448/37500]\n",
      "loss:   0.939209, acc:  46.274038 [29936/37500]\n",
      "loss:   0.941313, acc:  46.215278 [37424/37500]\n",
      "\n",
      "Train Loss: 0.941460, Train Acc: 46.219%\n",
      "Valid Loss: 0.932176, Valid Acc: 47.208%\n",
      "\n",
      "Break the best valid loss\n",
      "\t0.954676 -> 0.932176\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Learning Rate 0.000141\n",
      "---------------------------------\n",
      "loss:   0.936785, acc:  46.193910 [ 7472/37500]\n",
      "loss:   0.943673, acc:  46.113782 [14960/37500]\n",
      "loss:   0.948744, acc:  45.708689 [22448/37500]\n",
      "loss:   0.947166, acc:  45.713141 [29936/37500]\n",
      "loss:   0.945519, acc:  45.766560 [37424/37500]\n",
      "\n",
      "Train Loss: 0.945556, Train Acc: 45.784%\n",
      "Valid Loss: 0.934049, Valid Acc: 44.864%\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Learning Rate 0.000672\n",
      "---------------------------------\n",
      "loss:   0.932585, acc:  44.431090 [ 7472/37500]\n",
      "loss:   0.935611, acc:  45.118857 [14960/37500]\n",
      "loss:   0.932203, acc:  45.588497 [22448/37500]\n",
      "loss:   0.933645, acc:  45.562901 [29936/37500]\n",
      "loss:   0.934535, acc:  45.590278 [37424/37500]\n",
      "\n",
      "Train Loss: 0.934601, Train Acc: 45.587%\n",
      "Valid Loss: 0.929902, Valid Acc: 44.864%\n",
      "\n",
      "Break the best valid loss\n",
      "\t0.932176 -> 0.929902\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Learning Rate 0.001000\n",
      "---------------------------------\n",
      "loss:   0.927565, acc:  45.926816 [ 7472/37500]\n",
      "loss:   0.934103, acc:  45.499466 [14960/37500]\n",
      "loss:   0.934518, acc:  45.512821 [22448/37500]\n",
      "loss:   0.932509, acc:  45.709802 [29936/37500]\n",
      "loss:   0.933669, acc:  45.510150 [37424/37500]\n",
      "\n",
      "Train Loss: 0.933608, Train Acc: 45.512%\n",
      "Valid Loss: 0.929584, Valid Acc: 44.864%\n",
      "\n",
      "Break the best valid loss\n",
      "\t0.929902 -> 0.929584\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Learning Rate 0.000672\n",
      "---------------------------------\n",
      "loss:   0.940343, acc:  45.993590 [ 7472/37500]\n",
      "loss:   0.936563, acc:  45.673077 [14960/37500]\n",
      "loss:   0.934378, acc:  45.668625 [22448/37500]\n",
      "loss:   0.933710, acc:  45.689770 [29936/37500]\n",
      "loss:   0.933472, acc:  45.611645 [37424/37500]\n",
      "\n",
      "Train Loss: 0.933585, Train Acc: 45.587%\n",
      "Valid Loss: 0.929434, Valid Acc: 44.864%\n",
      "\n",
      "Break the best valid loss\n",
      "\t0.929584 -> 0.929434\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Learning Rate 0.000141\n",
      "---------------------------------\n",
      "loss:   0.934657, acc:  45.739850 [ 7472/37500]\n",
      "loss:   0.938515, acc:  45.719818 [14960/37500]\n",
      "loss:   0.933798, acc:  46.109330 [22448/37500]\n",
      "loss:   0.935072, acc:  45.866720 [29936/37500]\n",
      "loss:   0.933517, acc:  45.774573 [37424/37500]\n",
      "\n",
      "Train Loss: 0.933544, Train Acc: 45.768%\n",
      "Valid Loss: 0.929278, Valid Acc: 46.376%\n",
      "\n",
      "Break the best valid loss\n",
      "\t0.929434 -> 0.929278\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Learning Rate 0.000141\n",
      "---------------------------------\n",
      "loss:   0.930572, acc:  45.379274 [ 7472/37500]\n",
      "loss:   0.932956, acc:  45.392628 [14960/37500]\n",
      "loss:   0.933103, acc:  45.281339 [22448/37500]\n",
      "loss:   0.933668, acc:  45.205662 [29936/37500]\n",
      "loss:   0.933686, acc:  45.411325 [37424/37500]\n",
      "\n",
      "Train Loss: 0.933582, Train Acc: 45.419%\n",
      "Valid Loss: 0.929614, Valid Acc: 44.864%\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Learning Rate 0.000672\n",
      "---------------------------------\n",
      "loss:   0.935300, acc:  46.621261 [ 7472/37500]\n",
      "loss:   0.929542, acc:  45.853365 [14960/37500]\n",
      "loss:   0.931205, acc:  45.561788 [22448/37500]\n",
      "loss:   0.933798, acc:  45.479434 [29936/37500]\n",
      "loss:   0.933670, acc:  45.528846 [37424/37500]\n",
      "\n",
      "Train Loss: 0.933565, Train Acc: 45.536%\n",
      "Valid Loss: 0.929559, Valid Acc: 44.864%\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Learning Rate 0.001000\n",
      "---------------------------------\n",
      "loss:   0.941174, acc:  44.671474 [ 7472/37500]\n",
      "loss:   0.938025, acc:  45.292468 [14960/37500]\n",
      "loss:   0.934104, acc:  45.490563 [22448/37500]\n",
      "loss:   0.933005, acc:  45.292468 [29936/37500]\n",
      "loss:   0.933643, acc:  45.411325 [37424/37500]\n",
      "\n",
      "Train Loss: 0.933583, Train Acc: 45.403%\n",
      "Valid Loss: 0.929537, Valid Acc: 44.864%\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Learning Rate 0.000672\n",
      "---------------------------------\n",
      "loss:   0.926550, acc:  47.115385 [ 7472/37500]\n",
      "loss:   0.927221, acc:  46.167201 [14960/37500]\n",
      "loss:   0.930884, acc:  45.753205 [22448/37500]\n",
      "loss:   0.933186, acc:  45.419338 [29936/37500]\n",
      "loss:   0.933442, acc:  45.448718 [37424/37500]\n",
      "\n",
      "Train Loss: 0.933555, Train Acc: 45.429%\n",
      "Valid Loss: 0.929535, Valid Acc: 44.864%\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Learning Rate 0.000141\n",
      "---------------------------------\n",
      "loss:   0.926907, acc:  45.606303 [ 7472/37500]\n",
      "loss:   0.929414, acc:  45.125534 [14960/37500]\n",
      "loss:   0.933910, acc:  45.116631 [22448/37500]\n",
      "loss:   0.932775, acc:  45.496127 [29936/37500]\n",
      "loss:   0.933513, acc:  45.467415 [37424/37500]\n",
      "\n",
      "Train Loss: 0.933584, Train Acc: 45.443%\n",
      "Valid Loss: 0.929501, Valid Acc: 44.864%\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Learning Rate 0.000141\n",
      "---------------------------------\n",
      "loss:   0.941970, acc:  45.285791 [ 7472/37500]\n",
      "loss:   0.937455, acc:  45.579594 [14960/37500]\n",
      "loss:   0.936852, acc:  45.797721 [22448/37500]\n",
      "loss:   0.933608, acc:  45.699786 [29936/37500]\n",
      "loss:   0.933567, acc:  45.467415 [37424/37500]\n",
      "\n",
      "Train Loss: 0.933550, Train Acc: 45.464%\n",
      "Valid Loss: 0.929435, Valid Acc: 44.864%\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Learning Rate 0.000672\n",
      "---------------------------------\n",
      "loss:   0.935541, acc:  45.205662 [ 7472/37500]\n",
      "loss:   0.932619, acc:  45.572917 [14960/37500]\n",
      "loss:   0.934283, acc:  45.722044 [22448/37500]\n",
      "loss:   0.933897, acc:  45.726496 [29936/37500]\n",
      "loss:   0.933538, acc:  45.571581 [37424/37500]\n",
      "\n",
      "Train Loss: 0.933564, Train Acc: 45.571%\n",
      "Valid Loss: 0.929380, Valid Acc: 46.376%\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Learning Rate 0.001000\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:   0.925560, acc:  44.885150 [ 7472/37500]\n",
      "loss:   0.934887, acc:  45.032051 [14960/37500]\n",
      "loss:   0.932169, acc:  45.263533 [22448/37500]\n",
      "loss:   0.933435, acc:  45.332532 [29936/37500]\n",
      "loss:   0.933382, acc:  45.422009 [37424/37500]\n",
      "\n",
      "Train Loss: 0.933579, Train Acc: 45.432%\n",
      "Valid Loss: 0.929522, Valid Acc: 44.864%\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Learning Rate 0.000672\n",
      "---------------------------------\n",
      "loss:   0.937066, acc:  45.312500 [ 7472/37500]\n",
      "loss:   0.931503, acc:  45.779915 [14960/37500]\n",
      "loss:   0.931571, acc:  45.637464 [22448/37500]\n",
      "loss:   0.931970, acc:  45.572917 [29936/37500]\n",
      "loss:   0.933507, acc:  45.438034 [37424/37500]\n",
      "\n",
      "Train Loss: 0.933576, Train Acc: 45.427%\n",
      "Valid Loss: 0.929510, Valid Acc: 44.864%\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Learning Rate 0.000141\n",
      "---------------------------------\n",
      "loss:   0.930041, acc:  46.541132 [ 7472/37500]\n",
      "loss:   0.929994, acc:  45.966880 [14960/37500]\n",
      "loss:   0.930034, acc:  45.788818 [22448/37500]\n",
      "loss:   0.932608, acc:  45.723157 [29936/37500]\n",
      "loss:   0.933501, acc:  45.566239 [37424/37500]\n",
      "\n",
      "Train Loss: 0.933570, Train Acc: 45.549%\n",
      "Valid Loss: 0.929455, Valid Acc: 46.376%\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = np.inf\n",
    "best_valid_acc = 0\n",
    "\n",
    "early_stop = 0\n",
    "for epoch in range(configs['epochs']):\n",
    "    lr_now = optimizer.param_groups[0]['lr']\n",
    "    print(f'\\nEpoch {epoch+1}\\nLearning Rate {lr_now:>8f}\\n---------------------------------')\n",
    "    train_loss, train_acc = train_one_epoch(train_dl, model, loss_fn, optimizer, lr_scheduler, configs)\n",
    "    valid_loss, valid_acc = evaluate(valid_dl, model, loss_fn, configs)\n",
    "    print(f'\\nTrain Loss: {train_loss:>8f}, Train Acc: {train_acc*100:>3.3f}%')\n",
    "    print(f'Valid Loss: {valid_loss:>8f}, Valid Acc: {valid_acc*100:>3.3f}%\\n')\n",
    "    \n",
    "    if best_valid_loss > valid_loss:\n",
    "        print(f'Break the best valid loss\\n\\t{best_valid_loss:>8f} -> {valid_loss:>8f}\\n')\n",
    "        best_train_loss = train_loss\n",
    "        best_train_acc = train_acc\n",
    "        best_valid_loss = valid_loss\n",
    "        best_valid_acc = valid_acc\n",
    "        \n",
    "        torch.save(model.state_dict(), '../model/ka_s_model.pth')\n",
    "        \n",
    "        early_stop = 0\n",
    "    else:\n",
    "        early_stop += 1\n",
    "        \n",
    "    if early_stop >= configs['es_patience']:\n",
    "        break\n",
    "        \n",
    "print(f'Best Model')\n",
    "print(f'\\tbest_train_loss: {best_train_loss}, best_train_acc: {best_train_acc}')\n",
    "print(f'\\tbest_valid_loss: {best_valid_loss}, best_valid_acc: {best_valid_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fcdd5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "\n",
    "best_model = NNModel().to(device)\n",
    "best_model.load_state_dict(torch.load(\"../model/ka_s_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "592dfa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.939697, Test ACC: 0.484482\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_pred = evaluate(test_dl, best_model, loss_fn, configs, return_pred=True)\n",
    "\n",
    "print(f'Test Loss: {test_loss:>8f}, Test ACC: {test_acc:>8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac9269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
