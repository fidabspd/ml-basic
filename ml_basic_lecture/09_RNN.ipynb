{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf85yYfFJwhP",
        "colab_type": "text"
      },
      "source": [
        "# Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee0Vw5RJ_IOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OmcaAyM_1Eg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b3953cd7-158d-4dc4-941a-89b7870d9ef4"
      },
      "source": [
        "Numbers = [[i] for i in range(105)]\n",
        "Data = []\n",
        "Target = []\n",
        "\n",
        "for i in range(5, len(Numbers)):\n",
        "  Data.append(Numbers[i-5:i])\n",
        "  Target.append([Numbers[i][0] * 2])\n",
        "\n",
        "print(Data[:3], '\\n', Target[:3])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0], [1], [2], [3], [4]], [[1], [2], [3], [4], [5]], [[2], [3], [4], [5], [6]]] \n",
            " [[10], [12], [14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PeIYssJA6i4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c7026b7-cfef-4cb7-b7cb-9499aa74f260"
      },
      "source": [
        "Data = np.array(Data); Target = np.array(Target)\n",
        "Data = Data / 100.; Target = Target / 100.\n",
        "print(Data.shape, Target.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 5, 1) (100, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtSh54ScFNpv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbf65780-9b4a-45bf-a9d9-4c1b60d54b67"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Data, Target, test_size=0.2, random_state=0)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 5, 1) (20, 5, 1) (80, 1) (20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EMF15L7D-Nw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "59a28a48-3e66-4d15-9626-8ecf27c43228"
      },
      "source": [
        "input = Input(shape = X_train.shape[1:])\n",
        "x = LSTM(16, activation='tanh')(input)\n",
        "output = Dense(1)(x)\n",
        "\n",
        "model = Model(input, output)\n",
        "model.compile(optimizer='adam', loss='mae')\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 5, 1)]            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 16)                1152      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,169\n",
            "Trainable params: 1,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVL69Zv5FrJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55a987ae-942b-4894-f9cd-bc84b27a3c37"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=500, validation_split=0.2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 0s 228ms/step - loss: 0.9862 - val_loss: 1.0874\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9655 - val_loss: 1.0654\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9452 - val_loss: 1.0430\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9241 - val_loss: 1.0200\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9030 - val_loss: 0.9966\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8803 - val_loss: 0.9727\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8581 - val_loss: 0.9481\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8351 - val_loss: 0.9228\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8112 - val_loss: 0.8968\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7867 - val_loss: 0.8699\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7621 - val_loss: 0.8421\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7364 - val_loss: 0.8133\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7103 - val_loss: 0.7834\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6823 - val_loss: 0.7525\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6557 - val_loss: 0.7201\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6261 - val_loss: 0.6864\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5971 - val_loss: 0.6513\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5677 - val_loss: 0.6144\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5361 - val_loss: 0.5773\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5037 - val_loss: 0.5392\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4682 - val_loss: 0.5014\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4334 - val_loss: 0.4624\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3963 - val_loss: 0.4214\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3610 - val_loss: 0.3782\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3229 - val_loss: 0.3363\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2898 - val_loss: 0.2929\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2504 - val_loss: 0.2483\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2189 - val_loss: 0.2030\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1862 - val_loss: 0.1664\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1660 - val_loss: 0.1418\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1547 - val_loss: 0.1240\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1498 - val_loss: 0.1274\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1568 - val_loss: 0.1353\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1641 - val_loss: 0.1366\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1626 - val_loss: 0.1306\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1532 - val_loss: 0.1208\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1411 - val_loss: 0.1084\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1304 - val_loss: 0.1022\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1235 - val_loss: 0.1041\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1202 - val_loss: 0.1064\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1171 - val_loss: 0.1054\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1140 - val_loss: 0.1022\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1099 - val_loss: 0.0964\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1041 - val_loss: 0.0887\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0972 - val_loss: 0.0801\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0901 - val_loss: 0.0708\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0832 - val_loss: 0.0626\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0778 - val_loss: 0.0583\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0732 - val_loss: 0.0540\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0670 - val_loss: 0.0474\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.0601 - val_loss: 0.0419\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0536 - val_loss: 0.0382\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0472 - val_loss: 0.0317\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0403 - val_loss: 0.0249\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0339 - val_loss: 0.0191\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0272 - val_loss: 0.0156\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0245 - val_loss: 0.0158\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0172\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0227 - val_loss: 0.0186\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0239 - val_loss: 0.0196\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0242 - val_loss: 0.0195\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0244 - val_loss: 0.0194\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0194\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.0191\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0240 - val_loss: 0.0187\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0186\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0232 - val_loss: 0.0180\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0223 - val_loss: 0.0167\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0216 - val_loss: 0.0161\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0214 - val_loss: 0.0152\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0147\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0140\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0138\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.0138\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0134\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0194 - val_loss: 0.0133\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0193 - val_loss: 0.0130\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0129\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 0.0128\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0136\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0188 - val_loss: 0.0126\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0126\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0182 - val_loss: 0.0128\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0135\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0126\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0126\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0184 - val_loss: 0.0123\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0151\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0182 - val_loss: 0.0122\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0138\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0130\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0143\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0122\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0140\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0127\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0142\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0110\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0116\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0122\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0150\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0120\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0129\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0113\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0138\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0114\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0107\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0111\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0122\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0102\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0102\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0105\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0108\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0116\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0101\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0101\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0100\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0116\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0099\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0113\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0110\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0127\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0098\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0103\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0099\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0115\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0099\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0102\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0099\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0103\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0107\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0099\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0099\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0099\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0104\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0109\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0099\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0099\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0100\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0106\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0099\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0099\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0099\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0100\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0107\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0100\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0100\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0101\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0099\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0099\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0099\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0105\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0099\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0099\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0099\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0105\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0100\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0100\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0099\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0099\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0099\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0099\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0099\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0099\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0099\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0099\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0100\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0107\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0099\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0099\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0100\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0104\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0099\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0098\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0099\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0098\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0098\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0098\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0098\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0098\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0098\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0098\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0098\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0098\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0097\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0097\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0097\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0097\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0099\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0100\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0097\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0097\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0100\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0102\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0097\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0097\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0098\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0096\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0096\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0096\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0096\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0098\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0095\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0098\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0095\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0095\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0095\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0101\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0097\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0095\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0095\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0100\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0097\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0097\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0094\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0104\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0093\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0094\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0093\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0100\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0093\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0096\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0099\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0094\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0093\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0093\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0098\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0092\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0092\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0100\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0092\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0092\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0098\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0092\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0101\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0097\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0095\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0091\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0090\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0091\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0095\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0090\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0091\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0097\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0094\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0097\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0091\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0098\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0090\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0090\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0089\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0097\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0091\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0091\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0094\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0091\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0089\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0090\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0097\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.0110 - val_loss: 0.0089\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0091\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0091\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0093\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0088\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0087\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0091\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0091\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0092\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0088\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0100\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0088\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0104\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0089\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0092\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0087\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0093\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0087\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0095\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0089\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0089\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0092\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0087\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0087\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0085\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0092\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0086\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0088\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0089\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0091\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0085\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0084\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0086\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0084\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0087\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0086\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0084\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0086\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0083\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0083\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0087\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0084\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0082\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0084\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0082\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0083\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0082\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0084\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0082\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0085\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0083\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0082\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0081\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0084\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0081\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0084\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0089\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0081\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0083\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0081\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0088\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0080\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0110\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0083\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0085\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0091\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0081\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0093\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0081\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0083\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0086\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0079\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0079\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0082\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0079\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0080\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0080\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0081\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0079\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0085\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0078\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0082\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0085\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0084\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0089\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0086\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0085\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0077\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0083\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0077\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0078\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0078\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0076\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0077\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0081\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0082\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0078\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0082\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0080\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0075\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0079\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0074\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0075\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 0.0081\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0077\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0077\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0076\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0076\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0080\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0075\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0075\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0081\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0073\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0073\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0078\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0073\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0074\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0081\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0074\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0077\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0079\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0076\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0073\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0076\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0079\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0072\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0076\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0072\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0073\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0071\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0071\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0071\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0072\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.0072\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0078\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0074\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0072\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0079\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0073\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0086\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0070\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0076\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0076\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0078\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0075\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0070\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0075\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0069\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0078\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0072\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0072\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0073\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0070\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0073\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0073\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0070\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0070\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0069\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0068\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0069\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0069\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0074\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0068\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0068\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0070\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0070\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0068\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0072\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0068\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0070\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0067\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0067\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0071\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0067\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0069\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0067\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0068\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0074\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0069\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0068\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0072\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0069\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0070\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0093\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0085\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0068\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0078\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0065\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0067\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0071\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0065\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0065\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0065\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0065\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0065\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0068\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0066\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0071\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0070\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0067\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0068\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0065\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0084 - val_loss: 0.0073\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0071\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0063\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0065\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0066\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0063\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0062\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0068\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0093\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0065\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0061\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0091\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0067\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0061\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0089\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0061\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0065\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0061\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0067\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0066\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0063\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0069\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0074\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0061\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0089\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0083\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0062\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0066\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0060\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0063\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0066\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0068\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0103\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0069\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0060\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0098\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0059\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0064\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0077\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFI4LrC0GDwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "dab2dc20-109b-4474-e162-2d2c39915d8d"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(history.history['loss'])\n",
        "ax.plot(history.history['val_loss'])\n",
        "ax.legend(['train', 'test'])\n",
        "ax.set_title('Loss')\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_ylabel('mae')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX9jNZXSGY0k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "19d5b8de-d4ae-44ae-9cd9-716b87694032"
      },
      "source": [
        "y_pred = model.predict(X_test) * 100\n",
        "y_pred"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 61.36875 ],\n",
              "       [182.5555  ],\n",
              "       [ 15.866356],\n",
              "       [120.889725],\n",
              "       [161.36934 ],\n",
              "       [195.48517 ],\n",
              "       [ 41.74323 ],\n",
              "       [157.4183  ],\n",
              "       [118.82577 ],\n",
              "       [199.09169 ],\n",
              "       [116.76002 ],\n",
              "       [193.66693 ],\n",
              "       [167.24258 ],\n",
              "       [ 36.023724],\n",
              "       [ 24.86029 ],\n",
              "       [ 69.41709 ],\n",
              "       [ 53.424644],\n",
              "       [ 57.38252 ],\n",
              "       [ 75.51048 ],\n",
              "       [ 26.69382 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGNdqPesHMWl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "e35edaaf-e159-402b-dea3-cd433a386e4d"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(np.arange(len(y_test)), y_test*100, label='train')\n",
        "ax.scatter(np.arange(len(y_pred)), y_pred, marker='.', color='r', label='test')\n",
        "ax.legend()\n",
        "ax.set_xticks(list(range(0, 21, 4)))\n",
        "ax.set_xticklabels(list(range(0, 21, 4)))\n",
        "ax.set_title('Predict')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAeqklEQVR4nO3df3DddZ3v8efLJqXhxzWlrQxJ6W1dsROga1MjlovulmW9BXRpxZkKC15YHaN3Vdhdt2ur4u7OXBZms7Jexmvdoh3ggkAXSmG03lCRigwtmiYdWmljC1tK0loibBAhhSS87x/nm3IKKU1yTvLNN9/XYyZzzvl8z/ec9xeYF9/z+X6+n48iAjMzy4d3pF2AmZmNHYe+mVmOOPTNzHLEoW9mliMOfTOzHHHom5nliEPfbIgk3SLpfyXPPyypPe2azIbLoW8TjqS9knok/V7SwSSsTyznd0TEzyNi7hBquUrSo+X8brNSOPRtovqziDgRWAA0AF8v3iipIpWqzFLm0LcJLSI6gR8DZ0kKSV+QtBvYDSDpY5K2SeqW9JikPxzYV1K9pFZJL0m6G5hStG2RpI6i16dJWiepS9Lzkr4tqQ74LnBO8quje6yO2+xoHPo2oUk6DbgIaEualgIfBM6QVA+sAT4HTAP+DXhA0nGSJgPrgf8LnAz8O/CJo3zHJOCHwDPAbKAWuCsidgKfBzZHxIkRUT0qB2k2DA59m6jWJ2fWjwI/A/4pab8+Il6IiB6gEfi3iHg8Ivoj4lbgVWBh8lcJfCsieiPiHuCXR/mus4EaYHlEvBwRhyLC/fg2Lrlf0yaqpRHxk+IGSQDPFjX9V+BKSV8qaptMIcAD6IwjZyR85ijfdRrwTET0lVy12Sjzmb7lTXGIPwtcFxHVRX/HR8SdwAGgVsn/KRKzjvKZzwKzjnJx2NPY2rji0Lc8uxn4vKQPquAESR+VdBKwGegDrpZUKekSCt04g/kFhf9J3JB8xhRJ5ybbDgIzk2sEZqlz6FtuRUQL8Fng28B/AnuAq5JtrwGXJK9fAD4JrDvK5/QDfwa8B9gHdCTvB/gp8CvgN5J+OzpHYjZ08iIqZmb54TN9M7McceibmeWIQ9/MLEcc+mZmOTIubs6aPn16zJ49O+0yzMwyZevWrb+NiBnD2WdchP7s2bNpaWlJuwwzs0yRdLS7xI/K3TtmZjni0DczyxGHvplZjoyLPn0zs5Ho7e2lo6ODQ4cOpV3KqJoyZQozZ86ksrKy5M9y6JtZZnV0dHDSSScxe/ZsjpwQdeKICJ5//nk6OjqYM2dOyZ93zO6dZBm4hyU9KelXkq5J2k+WtFHS7uRxatIuSTdJ2iPpCUkLSq7SrMzWt3Vy7g0/Zc6KH3HuDT9lfVtn2iXZCBw6dIhp06ZN2MCHwjoQ06ZNK9uvmaH06fcBX46IMyisJvQFSWcAK4CHIuJ04KHkNcCFwOnJXyOwqiyVmpXJ+rZOVq7bTmd3T2GllO4eVq7b7uDPqIkc+APKeYzHDP2IOBARrcnzl4CdFNYAXQLcmrztVgprj5K03xYFW4BqSaeWrWKzEjU1t9PT28+Czp385ea1LOjcSU9vP03N7WmXZjbqhjV6R9JsoB54HDglIg4km34DnJI8r+XIJek6krY3f1ajpBZJLV1dXcMs22zk9nf3sKBzJ3fc9TX+5ue3c8ddX2NB5072d/ekXZplTHd3N9/5zneGvd9FF11Ed3f3KFR0bEMOfUknAvcCfxURvyvelqwjOqyJ+SNidUQ0RETDjBnDuovYyiDPfdo11VUs3Ledyv4+KuJ1Kvv7WLhvOzXVVWmXZhlztNDv63v75ZI3bNhAdXX1aJX1toY0ekdSJYXAvyMiBlYPOijp1Ig4kHTfPJe0d1JYKHrAzKTNxomBPu2e3n7gjT5tgKX1b/lRNuEsXzyXu9vn0/vYXdDfR++kCtrePZ/li+emXZqNsvVtnTQ1t7O/u4ea6iqWL55b0n/zK1as4KmnnmL+/PlUVlYyZcoUpk6dyq5du/j1r3/N0qVLefbZZzl06BDXXHMNjY2NwBtTz/z+97/nwgsv5EMf+hCPPfYYtbW13H///VRVjd4JyDFDP1kY+vvAzoi4sWjTA8CVwA3J4/1F7V+UdBfwQeDFom4gGweK+7QX7tvOllnzaK2to6m5PRehv7S+Fq5exjVTKnjPky3sOaOBTzZekotjz7PRONm54YYb2LFjB9u2bWPTpk189KMfZceOHYeHVq5Zs4aTTz6Znp4ePvCBD/CJT3yCadOmHfEZu3fv5s477+Tmm29m2bJl3HvvvVxxxRUlHOnbG8qZ/rnAp4DtkrYlbV+lEPZrJX0GeAZYlmzbAFxEYb3RV4C/KGvFVrLiPu3K5Ez38kuvo426tEsbM0vra1m66kupfX+5zzjt2AZOdooNXMAv1z/7s88++4ix9DfddBP33XcfAM8++yy7d+9+S+jPmTOH+fPnA/D+97+fvXv3lqWWozlm6EfEo8DRxgudP8j7A/hCiXXZKKqprmLh5jf6tEn6tA+e6VsqxsLAGWfd3h0sSX5prXz5NSAf3WtpOdqF+nJewD/hhBMOP9+0aRM/+clP2Lx5M8cffzyLFi0adKz9cccdd/j5pEmT6OkZ3QEFviM3h9ynna6m5nbq9u54yy+tpubJDv1RVFNdRecgAV/KBfyTTjqJl156adBtL774IlOnTuX4449n165dbNmyZcTfU04O/Rxyn3a69nf3sGTfW39prarNT/daGpYvnntEnz5AVeWkkk52pk2bxrnnnstZZ51FVVUVp5xyyuFtF1xwAd/97nepq6tj7ty5LFy4sKT6y8Whn1Np92nnWU11FVtmzaN3UsXhX1pbZs3zkNFRNnBSU+5rKT/4wQ8GbT/uuOP48Y9/POi2gX776dOns2PHjsPtf/u3f1tSLUPh0DcbY8sXz2Xly69x+aXXHR49tXP2WVzv7rVRt7S+Nve/aB36ZmPsjTPOyayqraOmuorrPXrHxohD3ywFPuO0tHjlLDOzHHHom5nliEPfzCxHHPpmZiM00qmVAb71rW/xyiuvlLmiY8tt6Od5amEzK48shn4uR+947hMzK4fiqZU/8pGP8K53vYu1a9fy6quv8vGPf5x//Md/5OWXX2bZsmV0dHTQ39/Ptddey8GDB9m/fz/nnXce06dP5+GHHx6zmnMZ+p77xCzHNm+GTZtg0SI455ySPqp4auUHH3yQe+65h1/84hdEBBdffDGPPPIIXV1d1NTU8KMf/QgozMnzzne+kxtvvJGHH36Y6dOnl35Mw5DL7p393T2Drpzk5fLMJrjNm+H88+HaawuPmzeX7aMffPBBHnzwQerr61mwYAG7du1i9+7dzJs3j40bN/KVr3yFn//857zzne8s23eORC7P9D33iVlObdoEr70G/f2Fx02bSj7bHxARrFy5ks997nNv2dba2sqGDRv4+te/zvnnn883vvGNsnznSOQy9D33iVlOLVoEkycXAn/y5MLrEhRPrbx48WKuvfZaLr/8ck488UQ6OzuprKykr6+Pk08+mSuuuILq6mq+973vHbHvWHfv5DL0PfeJWU6dcw489FDZ+vSLp1a+8MIL+fM//3POST7zxBNP5Pbbb2fPnj0sX76cd7zjHVRWVrJq1SoAGhsbueCCC6ipqRnTC7kqLHSVroaGhmhpaUm7DDPLmJ07d1JXl491CAY7VklbI6JhOJ9zzAu5ktZIek7SjqK2uyVtS/72DqydK2m2pJ6ibd8dTjFmZja6htK9cwvwbeC2gYaI+OTAc0nfBF4sev9TETG/XAWamVn5DGVh9EckzR5smyQBy4A/KW9ZZmZDExEUomjiKmc3fKnj9D8MHIyI3UVtcyS1SfqZpA8fbUdJjZJaJLV0dXWVWIaZ5dGUKVN4/vnnyxqK401E8PzzzzNlypSyfF6po3cuA+4sen0AmBURz0t6P7Be0pkR8bs37xgRq4HVULiQW2IdZpZDM2fOpKOjg4l+4jhlyhRmzpxZls8acehLqgAuAd4/0BYRrwKvJs+3SnoKeC/goTlmVnaVlZXMmTMn7TIypZTunT8FdkVEx0CDpBmSJiXP3w2cDjxdWolmZlYuQxmyeSewGZgrqUPSZ5JNl3Jk1w7AHwFPJEM47wE+HxEvlLNgMzMbuaGM3rnsKO1XDdJ2L3Bv6WWZmdloyOU0DGZZt76tkw2r1/GeJ1vYc0YDFzVe4mlEbEgc+mYZs76tk7tvWsua21cU1oN47C4+fagPrl7m4LdjyuV8+mZZ1tTcTv3T245YD6L+6W00NbenXZplgEPfLGP2d/ccXg+iT+84vB6EFwGyoXD3jlnG1FRX0UrdEetBtNbWUetFgGwIHPpmGbN88VxWrttOa20drbWFqXarKiex3IsA2RA49LOsjAs8W3a8sQhQO/u7e6iprmK5FwGyIXLoZ9TPbnmADzYuo6Kvl76KSh5fvZY/vuritMuyMbK0vtYhbyPiC7kZtL6tk6233UdFXy8V8ToVfb1sve0+1rd1pl2amY1zDv0Mampu59HaM48YvfFo7Zkesmdmx+TunQza391DZ+1bR28oa0P2fE3CbMw59DOoprqKzu6eI0ZvDLRnha9JmKXD3TsZtHzxXKoqJx3RlqUhe74mYZYeh34GLa2v5fpL5lFbXYWA2uoqrr9kXmZGc/iahFl63L2TUVkesjdhrkmYZZBD38bcRLgmYZZV7t6xMZf1axJmWTaU5RLXSHpO0o6itn+Q1ClpW/J3UdG2lZL2SGqXtHi0Crfsyvo1CbMsG0r3zi3At4Hb3tT+rxHxL8UNks6gsHbumUAN8BNJ742I/jLUahNIlq9JmGXZMc/0I+IRYKiLmy8B7oqIVyPiP4A9wNkl1GdmZmVUSp/+FyU9kXT/TE3aaoFni97TkbS9haRGSS2SWrq6ukoow8zMhmqkob8K+ANgPnAA+OZwPyAiVkdEQ0Q0zJgxY4RlmJnZcIwo9CPiYET0R8TrwM280YXTCZxW9NaZSZuZmY0DIwp9SacWvfw4MDCy5wHgUknHSZoDnA78orQSzcysXI45ekfSncAiYLqkDuDvgUWS5gMB7AU+BxARv5K0FngS6AO+4JE7ZmbjhyIi7RpoaGiIlpaWtMswM8sUSVsjomE4+/iOXDOzHHHom5nliEPfzCxHHPpmZjni0DczyxGHvplZjjj0zcxyxKFvZpYjDn0zsxxx6JuZ5YhD38wsRxz6ZmY54tA3M8sRh76ZWY449M3McsShb2aWIw59M7McceibmeXIMUNf0hpJz0naUdTWJGmXpCck3SepOmmfLalH0rbk77ujWbyZmQ3PUM70bwEueFPbRuCsiPhD4NfAyqJtT0XE/OTv8+Up08zMyuGYoR8RjwAvvKntwYjoS15uAWaOQm1mZlZm5ejT/zTw46LXcyS1SfqZpA8fbSdJjZJaJLV0dXWVoQwzMzuWkkJf0teAPuCOpOkAMCsi6oG/AX4g6b8Mtm9ErI6IhohomDFjRillmJnZEFWMdEdJVwEfA86PiACIiFeBV5PnWyU9BbwXaCm91IllfVsnG1av4z1PtrDnjAYuaryEpfW1aZdlZhPciEJf0gXA3wF/HBGvFLXPAF6IiH5J7wZOB54uS6UTyPq2Tu6+aS1rbl9BZX8fvY/dxacP9cHVyxz8ZjaqhjJk805gMzBXUoekzwDfBk4CNr5paOYfAU9I2gbcA3w+Il4Y9INzrKm5nfqnt1HZ30dFvE5lfx/1T2+jqbk97dIyY31bJ+fe8FPmrPgR597wU9a3daZdklkmHPNMPyIuG6T5+0d5773AvaUWNdHt7+5hy6x59E6qgP4+eidVsGXWPPZ396RdWiasb+tk5brt1O3dwZJ929kyax4rX34NwL+UzI5hxH36NnI11VW0Usfll17HwiS0WmvrqK2uSru0TGhqbqdu7w7uuOtrhe6xSRVcful1NDVPduibHYNDPwXLF89l5brttNbW0VpbB0BV5SSWL56bcmXZsL+7hyX7th/uHqO/j4X7trMq+Wc5Fnwh3rLKoZ+CgXBoam5nf3cPNdVVLF8816ExRDXVVYN2j9WM0S8lX4i3LHPop2Rpfa0DYoSWL57LypdfO6J7bOfss7h+jH4pNTW3s6ToQjyHL8S/z/9Obdxz6FvmvPFLaTKrauuoqa7i+jH8peQL8ZZlDn3LpDR/KflCvGWZQ99smHwh3rLMoW82TL4Qb1nm0DcbAV+It6zycolmZjni0DczyxGHvplZjjj0zcxyxKFvZpYjDn0zsxxx6JuZ5YhD38wsR4YU+pLWSHpO0o6itpMlbZS0O3mcmrRL0k2S9kh6QtKC0SrezMyGZ6hn+rcAF7ypbQXwUEScDjyUvAa4kMKC6KcDjcCq0ss0M7NyGFLoR8QjwJsXOF8C3Jo8vxVYWtR+WxRsAaolnVqOYs3MrDSl9OmfEhEHkue/AU5JntcCzxa9ryNpMzOzlJXlQm5EBBDD2UdSo6QWSS1dXV3lKMPMzI6hlNA/ONBtkzw+l7R3AqcVvW9m0naEiFgdEQ0R0TBjxowSyjAzs6EqJfQfAK5Mnl8J3F/U/j+SUTwLgReLuoHMzCxFQ5pPX9KdwCJguqQO4O+BG4C1kj4DPAMsS96+AbgI2AO8AvxFmWs2M7MRGlLoR8RlR9l0/iDvDeALpRRlZmajw3fkmpnliEPfzCxHHPpmZjni0DczyxGHvplZjjj0zcxyxKFvZpYjDn0zsxxx6JuZ5YhD38wsRxz6ZmY54tA3M8sRh76ZWY449M3McsShb2aWIw59M7McceibmeXIkFbOMjOzN6xv66SpuZ393T3UVFexfPFcltbXpl3WkIw49CXNBe4uano38A2gGvgs0JW0fzUiNoy4QjOzcWR9Wycr122np7cfgM7uHlau2w6QieAfcfdORLRHxPyImA+8n8Ii6Pclm/91YJsD38wmkqbmdnp6+1nQuZO/3LyWBZ076entp6m5Pe3ShqRc3TvnA09FxDOSyvSRZmbjz/7uHhZ07uSOu75GZX8fvZMquPzS62ijLu3ShqRcF3IvBe4sev1FSU9IWiNp6mA7SGqU1CKppaura7C3mJmNOzXVVSzct53K/j4q4nUq+/tYuG87NdVVaZc2JCWHvqTJwMXAvydNq4A/AOYDB4BvDrZfRKyOiIaIaJgxY0apZZiZjYnli+fS9u759E6qoE/voHdSBW3vns/yxXPTLm1IytG9cyHQGhEHAQYeASTdDPywDN9hZhNIlke/LK2vhauXcc2UCt7zZAt7zmjgk42XZKb+coT+ZRR17Ug6NSIOJC8/Duwow3eY2QSR9dEvUKhz6aovpV3GiJTUvSPpBOAjwLqi5n+WtF3SE8B5wF+X8h1mNrFkffRL1pV0ph8RLwPT3tT2qZIqMrMJLeujX7LO0zCY2ZjK+uiXrHPom9mYyvrol6zz3DtmNqayPvol6xQRaddAQ0NDtLS0pF2GmVmmSNoaEQ3D2cfdO2ZmOZLp7p0s3+BhZpaGzIb+RLjBw8xsrGW2e8c3eJiZDV9mz/R9g4eZ2fBlNvRrqqtYuPmNGzxIbvA4eOaCtEszs3Euz9cDM9u94xs8zGwkBq4Hdnb3ELxxPXB9W2fapY2JzJ7p+wYPMxuJ4uuBC/dtZ8usebTW1tHU3J6L/Mhs6EO2pzc1s3Tk/XpgpkPfzPKplD75vF8PzGyfvpnlU6l98nm/HugzfTPLlFL75PN+PdChb2aZUo4++TxfDyy5e0fS3mR5xG2SWpK2kyVtlLQ7eZxaeqlmZl6EpVTl6tM/LyLmF03xuQJ4KCJOBx5KXpuZlSzvffKlGq3unSXAouT5rcAm4Cuj9F1mliN575MvVcmLqEj6D+A/gQD+LSJWS+qOiOpku4D/HHg9GC+iYmY2fCNZRKUcZ/ofiohOSe8CNkraVbwxIkLSW/7PIqkRaASYNWtWGcowM7NjKblPPyI6k8fngPuAs4GDkk4FSB6fG2S/1RHREBENM2bMKLUMMzMbgpJCX9IJkk4aeA78d2AH8ABwZfK2K4H7S/keMzMrj1K7d04B7it021MB/CAi/p+kXwJrJX0GeAZYVuL3mJlZGZQU+hHxNPC+QdqfB84v5bPNzKz8fEeujUieF6EwyzKHvg3bwIRXdXt3sCSZ+2Tly68BXpTebLxz6NuwNTW3U7d3x1vmPmlqnuzQNxvnPLWyDdv+7p5B5z7Z392TdmlmdgwOfRu2muoqtsyad8TcJ1tmzfOEV2YZ4O4dG7bli+ey8uXXuPzS6w7PZ75z9llc7wmvzMY9h74N20C/fVPzZFbV1lFTXcX1Hr1jlgkOfRuRpfW1DvkM85Db/HLom+WMh9zmm0PfLGc85DbfPHrHLGc85DbfHPpmOeMht/nm7h2znPGQ23xz6JvljIfc5ptD3yyHPOQ2v9ynb2aWIw59M7MccfeOmdkYW9/WyYbV63jPky3sOaOBixovGbPuthGHvqTTgNsorJMbwOqI+N+S/gH4LNCVvPWrEbGh1ELNzCaC9W2d3H3TWtbcvqJwc9xjd/HpQ31w9bIxCf5SzvT7gC9HRKukk4CtkjYm2/41Iv6l9PLMbDxK80w165qa21ny9LbDN8fR30f909toan7f+A79iDgAHEievyRpJ+B/62YTXNpnqlm3v7vn8M1xJNNgbJk1b8zuiC7LhVxJs4F64PGk6YuSnpC0RtLUo+zTKKlFUktXV9dgbzGzcaipuZ36ojPVysNnqu1pl5YJNdVVtNbWcfml13Hjh6/g8kuvozW5X2IslBz6kk4E7gX+KiJ+B6wC/gCYT+GXwDcH2y8iVkdEQ0Q0zJgxo9QyzGyMFJ+pFk/j4Ll7hmb54rlUVU6itbaO75yzjNbaOqoqJ7F8jO6ILmn0jqRKCoF/R0SsA4iIg0XbbwZ+WFKFZjau1FRX0UrdEdM4tNbWUeu5e4bkjTui01nPoJTROwK+D+yMiBuL2k9N+vsBPg7sKK1EMxtPli+ey8p122mtraO1tg5gTM9UJ4I074gu5Uz/XOBTwHZJ25K2rwKXSZpPYRjnXuBzJVVoZuNK2meqVhpFRNo10NDQEC0tLWmXYWaWKZK2RkTDcPbxNAxmZjni0DczyxGHfik2b4brry88mpllgCdcG6Gf3fIAH2xcRkVfL30VlTy+ei1/fNXFaZdlZva2fKY/AuvbOtl6231U9PVSEa9T0dfL1tvuY31bZ9qlmZm9LYf+CDQ1t/No7ZlH3JH4aO2Zvg3dzMY9d++MwP7uHjpr33pHonwbupmNcw79EaiprqKzu+eIOxIH2s3MxjN374zAwIRJxXwbupllgc/0R8C3oZtZVjn0RyjNCZPMzEbK3TtmZjni0DczyxGHvplZjjj0zcxyxKFvZpYj42IRFUldwDMlfMR04LdlKidr8nzs4OP38ef7+OdGxEnD2WFcDNmMiBml7C+pZbirx0wUeT528PH7+H38w93H3TtmZjni0Dczy5GJEvqr0y4gRXk+dvDx+/jzbdjHPy4u5JqZ2diYKGf6ZmY2BA59M7McyXToS7pAUrukPZJWpF1PGiRNktQm6Ydp1zLWJP21pF9J2iHpTklT0q5pNElaI+k5STuK2pok7ZL0hKT7JFWnWeNoGuz4k/YvJf8MfiXpn9Oqb7RJOk3Sw5KeTI71mqT9ZEkbJe1OHqe+3edkNvQlTQL+D3AhcAZwmaQz0q0qFdcAO9MuYqxJqgWuBhoi4ixgEnBpulWNuluAC97UthE4KyL+EPg1sHKsixpDt/Cm45d0HrAEeF9EnAn8Swp1jZU+4MsRcQawEPhCknkrgIci4nTgoeT1UWU29IGzgT0R8XREvAbcReFffm5Imgl8FPhe2rWkpAKoklQBHA/sT7meURURjwAvvKntwYjoS15uAWaOeWFjZLDjB/4ncENEvJq857kxL2yMRMSBiGhNnr9E4WSvlkLu3Zq87VZg6dt9TpZDvxZ4tuh1R9KWJ98C/g54Pe1CxlpEdFI4q9sHHABejIgH060qdZ8Gfpx2EWPsvcCHJT0u6WeSPpB2QWNB0mygHngcOCUiDiSbfgOc8nb7Zjn0c03Sx4DnImJr2rWkIem3XALMAWqAEyRdkW5V6ZH0NQo//+9Iu5YxVgGcTKG7YzmwVpLSLWl0SToRuBf4q4j4XfG2KIzBf9tx+FkO/U7gtKLXM5O2vDgXuFjSXgpdW38i6fZ0SxpTfwr8R0R0RUQvsA74bynXlApJVwEfAy6P/N140wGsi4JfUPjVOz3lmkaNpEoKgX9HRKxLmg9KOjXZfirwtl1cWQ79XwKnS5ojaTKFi3gPpFzTmImIlRExMyJmUzj2n0ZEns509wELJR2fnNmdTz4vaF9AoYvv4oh4Je16UrAeOA9A0nuByUzQWTeT/86/D+yMiBuLNj0AXJk8vxK4/+0+Z1zMsjkSEdEn6YtAM4WRG2si4lcpl2VjJCIel3QP0EqhW6ONCX5LvqQ7gUXAdEkdwN9TGK1zHLAx6dXYEhGfT63IUXSU418DrEmGcb4GXDmBf+2cC3wK2C5pW9L2VeAGCt1an6EwRf2yt/sQT8NgZpYjWe7eMTOzYXLom5nliEPfzCxHHPpmZjni0DczyxGHvplZjjj0zcxy5P8DCrBR0nuc1FAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZBOadGOH_dY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cddee1c-f60d-4157-ecbf-09fbba9c5b93"
      },
      "source": [
        "test_data = [[i] for i in range(35, 40)]\n",
        "\n",
        "x = np.array(test_data) / 100\n",
        "x = x.reshape(-1, 5, 1)\n",
        "\n",
        "(model.predict(x)*100).tolist()  # 80이 나와야함"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[79.59547424316406]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}